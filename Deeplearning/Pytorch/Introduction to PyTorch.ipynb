{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0e94eac",
   "metadata": {},
   "source": [
    "### Why PyTorch?\n",
    "- Easy to use\n",
    "- Strong GPU support - models run fast\n",
    "- Many algorithms are already implemented\n",
    "- Automatic differentiation\n",
    "- Similar to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3ff6c3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f5d2c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "Tensor:  tensor([[-0.6909,  0.5419],\n",
      "        [-2.1515, -0.7830]])\n",
      "Shape:  torch.Size([2, 2])\n",
      "Dimension:  2\n"
     ]
    }
   ],
   "source": [
    "# Tensor in pytorch\n",
    "x = torch.tensor([1,2,3])\n",
    "print(x)\n",
    "\n",
    "# Random Tensor\n",
    "x = torch.randn((2, 2))\n",
    "print(\"Tensor: \", x)\n",
    "print(\"Shape: \", x.shape)\n",
    "print(\"Dimension: \", x.dim())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "963b4ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 8, 12],\n",
      "        [ 4,  6]])\n"
     ]
    }
   ],
   "source": [
    "# Matrix Multiplication\n",
    "x = torch.tensor([[2,2],[1,1]])\n",
    "y = torch.tensor([[1,2],[3,4]])\n",
    "print(torch.matmul(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f493889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4])\n",
      "tensor(20)\n",
      "tensor([20])\n"
     ]
    }
   ],
   "source": [
    "# Element-wise Multiplication\n",
    "print(x * 2)\n",
    "\n",
    "x = torch.tensor([2])\n",
    "y = torch.tensor([10])\n",
    "print(torch.matmul(x, y))\n",
    "print((x * y)) # Same as matmul, needs unpacking through * operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1680f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "tensor([[1., 0.],\n",
      "        [0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# Zero, One and Identity tensors\n",
    "a = torch.zeros((2,2))\n",
    "print(a)\n",
    "b = torch.ones((2,2))\n",
    "print(b)\n",
    "c = torch.eye((2))\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "585ff6bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.1381)\n"
     ]
    }
   ],
   "source": [
    "# Forward Propagation: Intuition\n",
    "# A(10,10)-----\\\n",
    "#               \\ + U(10,10)____\n",
    "# B(10, 10)-----/               \\ matmul V (10,10)-----> Average W(1) \n",
    "#                               /\n",
    "# C(10, 10)-------------------/\n",
    "\n",
    "A = torch.rand(10, 10)\n",
    "B = torch.rand(10, 10)\n",
    "C = torch.rand(10, 10)\n",
    "\n",
    "U = A + B\n",
    "V = torch.matmul(U, C)\n",
    "\n",
    "print(torch.mean(V))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e270c24",
   "metadata": {},
   "source": [
    "### Derivative Example - Backward Pass\n",
    "\n",
    "![](derivative.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad1e3f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward U: 3.0\n",
      "Forward V: 9.0\n",
      "Gradient of A: 3.0\n",
      "Gradient of B: 3.0\n",
      "Gradient of C: 3.0\n"
     ]
    }
   ],
   "source": [
    "# Backpropagation in PyTorch\n",
    "# requires_grad=True tells pytorch that we need derivatives of respective tensor\n",
    "A = torch.tensor(2., requires_grad=True)\n",
    "B = torch.tensor(1., requires_grad=True)\n",
    "C = torch.tensor(3., requires_grad=True)\n",
    "\n",
    "U = A + B\n",
    "V = U * C\n",
    "\n",
    "# Compute the Derivatives\n",
    "V.backward()\n",
    "\n",
    "print(\"Forward U: {}\".format(U))\n",
    "print(\"Forward V: {}\".format(V))\n",
    "\n",
    "# Print the Gradients of the tensors\n",
    "print(\"Gradient of A: {}\".format(A.grad))\n",
    "print(\"Gradient of B: {}\".format(B.grad))\n",
    "print(\"Gradient of C: {}\".format(C.grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "84c0f5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([227.7676], grad_fn=<SqueezeBackward3>)\n",
      "tensor([46.7401, 44.6531, 60.3256, 50.8371, 46.1656, 43.8929, 54.2853, 36.6519,\n",
      "        57.5263, 48.2738])\n"
     ]
    }
   ],
   "source": [
    "# Fully Connected NN\n",
    "torch.manual_seed(0)\n",
    "input_layer = torch.rand(10, requires_grad=True)\n",
    "\n",
    "w1 = torch.rand(10, 20)\n",
    "w2 = torch.rand(20, 20)\n",
    "w3 = torch.rand(20, 1)\n",
    "h1 = torch.matmul(input_layer, w1)\n",
    "h2 = torch.matmul(h1, w2)\n",
    "output_layer = torch.matmul(h2, w3)\n",
    "\n",
    "output_layer.backward()\n",
    "\n",
    "print(output_layer)\n",
    "print(input_layer.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "59ebbf14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9461, 0.9648, 0.9577, 0.9819, 1.0730, 1.0747, 0.9394, 1.0397, 1.0242,\n",
      "        0.9985])\n"
     ]
    }
   ],
   "source": [
    "ip = torch.rand(784)\n",
    "weight_1 = torch.rand(784, 200)\n",
    "weight_2 = torch.rand(200, 10)\n",
    "\n",
    "hidden_1 = torch.matmul(ip, weight_1)\n",
    "op = torch.matmul(hidden_1, weight_2)\n",
    "\n",
    "print(op/torch.mean(op))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae2298a",
   "metadata": {},
   "source": [
    "### Building a NN - PyTorch style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "2ee42e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4428], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NN, self).__init__()\n",
    "        self.l1 = nn.Linear(10, 20)\n",
    "        self.l2 = nn.Linear(20, 20)\n",
    "        self.l3 = nn.Linear(20, 1)\n",
    "        self.out = nn.Sigmoid()\n",
    "        \n",
    "    # Forward Pass\n",
    "    def forward(self, x):\n",
    "        x = self.l1(x)\n",
    "        x = self.l2(x)\n",
    "        x = self.l3(x)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "    \n",
    "# Instantiate NN class\n",
    "input_layer = torch.rand(10, requires_grad=True)\n",
    "net = NN()\n",
    "result = net(input_layer)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
